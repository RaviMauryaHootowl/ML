{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing Basic Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset and converting into array\n",
    "\n",
    "X = dataset.iloc[: , 3:13].values   # from CreditScore to Estimated Salary\n",
    "y = dataset.iloc[:, 13].values      # only Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
       "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
       "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
       "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
       "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Now we need to do Label Encoding and One Hot Encoding '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Now we need to do Label Encoding and One Hot Encoding '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will do Label Encoding in Gender Column\n",
    "# For this we need to create a LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "X[:, 2] = label_encoder.fit_transform(X[:, 2])\n",
    "\n",
    "# here female became 0 and male became 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 0, ..., 1, 1, 101348.88],\n",
       "       [608, 'Spain', 0, ..., 0, 1, 112542.58],\n",
       "       [502, 'France', 0, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 'France', 0, ..., 0, 1, 42085.58],\n",
       "       [772, 'Germany', 1, ..., 1, 0, 92888.52],\n",
       "       [792, 'France', 0, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for countries we need to Label Encode and then Hot Encode ( for dummy variables )\n",
    "# so we can use directly ColumnTransformer \n",
    "\n",
    "ct1 = ColumnTransformer(transformers=[('oh', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = ct1.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, ..., 1, 1, 101348.88],\n",
       "       [0.0, 0.0, 1.0, ..., 0, 1, 112542.58],\n",
       "       [1.0, 0.0, 0.0, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [1.0, 0.0, 0.0, ..., 0, 1, 42085.58],\n",
       "       [0.0, 1.0, 0.0, ..., 1, 0, 92888.52],\n",
       "       [1.0, 0.0, 0.0, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X     \n",
    "#now to columns becomes['France', 'Germany', 'Spain', 'CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts',\n",
    "#                       'HasCrCard', 'IsActiveMember', 'Estimated Salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but to avoid the dummy variable trap... let's remove the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 619, ..., 1, 1, 101348.88],\n",
       "       [0.0, 1.0, 608, ..., 0, 1, 112542.58],\n",
       "       [0.0, 0.0, 502, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [0.0, 0.0, 709, ..., 0, 1, 42085.58],\n",
       "       [1.0, 0.0, 772, ..., 1, 0, 92888.52],\n",
       "       [0.0, 0.0, 792, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "#now to columns becomes['Germany', 'Spain', 'CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts',\n",
    "#                       'HasCrCard', 'IsActiveMember', 'Estimated Salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  NOW LETS SPLIT THE DATASET INTO TRAIN AND TEST  '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''  NOW LETS SPLIT THE DATASET INTO TRAIN AND TEST  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size:  8000\n",
      "Testing size:  2000\n"
     ]
    }
   ],
   "source": [
    "print('Training size: ' , len(X_train))\n",
    "print('Testing size: ' , len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FEATURE SCALING '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''FEATURE SCALING '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5698444 ,  1.74309049,  0.16958176, ...,  0.64259497,\n",
       "        -1.03227043,  1.10643166],\n",
       "       [ 1.75486502, -0.57369368, -2.30455945, ...,  0.64259497,\n",
       "         0.9687384 , -0.74866447],\n",
       "       [-0.5698444 , -0.57369368, -1.19119591, ...,  0.64259497,\n",
       "        -1.03227043,  1.48533467],\n",
       "       ...,\n",
       "       [-0.5698444 , -0.57369368,  0.9015152 , ...,  0.64259497,\n",
       "        -1.03227043,  1.41231994],\n",
       "       [-0.5698444 ,  1.74309049, -0.62420521, ...,  0.64259497,\n",
       "         0.9687384 ,  0.84432121],\n",
       "       [ 1.75486502, -0.57369368, -0.28401079, ...,  0.64259497,\n",
       "        -1.03227043,  0.32472465]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------- ANN Step ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the ANN Model\n",
    "# We can call the model anything, but since we are doing classification let's call it classifier\n",
    "\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "\n",
    "classifier.add(Dense(6, input_dim = 11, kernel_initializer = 'uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(6, kernel_initializer = 'uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output layer\n",
    "classifier.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/300\n",
      "7200/7200 [==============================] - 1s 145us/step - loss: 0.5582 - accuracy: 0.7950 - val_loss: 0.4336 - val_accuracy: 0.7950\n",
      "Epoch 2/300\n",
      "7200/7200 [==============================] - 1s 73us/step - loss: 0.4361 - accuracy: 0.7961 - val_loss: 0.4215 - val_accuracy: 0.7950\n",
      "Epoch 3/300\n",
      "7200/7200 [==============================] - 1s 70us/step - loss: 0.4312 - accuracy: 0.7961 - val_loss: 0.4172 - val_accuracy: 0.7950\n",
      "Epoch 4/300\n",
      "7200/7200 [==============================] - 1s 70us/step - loss: 0.4285 - accuracy: 0.7961 - val_loss: 0.4137 - val_accuracy: 0.7950\n",
      "Epoch 5/300\n",
      "7200/7200 [==============================] - 1s 71us/step - loss: 0.4260 - accuracy: 0.7961 - val_loss: 0.4102 - val_accuracy: 0.7950\n",
      "Epoch 6/300\n",
      "7200/7200 [==============================] - 1s 70us/step - loss: 0.4235 - accuracy: 0.7961 - val_loss: 0.4057 - val_accuracy: 0.7950\n",
      "Epoch 7/300\n",
      "7200/7200 [==============================] - 1s 73us/step - loss: 0.4216 - accuracy: 0.8074 - val_loss: 0.4033 - val_accuracy: 0.8238\n",
      "Epoch 8/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4204 - accuracy: 0.8174 - val_loss: 0.4006 - val_accuracy: 0.8250\n",
      "Epoch 9/300\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.4192 - accuracy: 0.8203 - val_loss: 0.3991 - val_accuracy: 0.8363\n",
      "Epoch 10/300\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.4179 - accuracy: 0.8253 - val_loss: 0.3983 - val_accuracy: 0.8375\n",
      "Epoch 11/300\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.4170 - accuracy: 0.8257 - val_loss: 0.3965 - val_accuracy: 0.8363\n",
      "Epoch 12/300\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.4162 - accuracy: 0.8278 - val_loss: 0.3958 - val_accuracy: 0.8375\n",
      "Epoch 13/300\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.4155 - accuracy: 0.8283 - val_loss: 0.3944 - val_accuracy: 0.8413\n",
      "Epoch 14/300\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.4147 - accuracy: 0.8282 - val_loss: 0.3933 - val_accuracy: 0.8425\n",
      "Epoch 15/300\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.4138 - accuracy: 0.8297 - val_loss: 0.3920 - val_accuracy: 0.8388\n",
      "Epoch 16/300\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.4134 - accuracy: 0.8286 - val_loss: 0.3922 - val_accuracy: 0.8425\n",
      "Epoch 17/300\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.4132 - accuracy: 0.8296 - val_loss: 0.3904 - val_accuracy: 0.8425\n",
      "Epoch 18/300\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.4124 - accuracy: 0.8300 - val_loss: 0.3920 - val_accuracy: 0.8462\n",
      "Epoch 19/300\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.4123 - accuracy: 0.8315 - val_loss: 0.3894 - val_accuracy: 0.8450\n",
      "Epoch 20/300\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.4116 - accuracy: 0.8319 - val_loss: 0.3892 - val_accuracy: 0.8450\n",
      "Epoch 21/300\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.4112 - accuracy: 0.8315 - val_loss: 0.3877 - val_accuracy: 0.8438\n",
      "Epoch 22/300\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.4110 - accuracy: 0.8325 - val_loss: 0.3871 - val_accuracy: 0.8425\n",
      "Epoch 23/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4104 - accuracy: 0.8332 - val_loss: 0.3864 - val_accuracy: 0.8425\n",
      "Epoch 24/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4101 - accuracy: 0.8335 - val_loss: 0.3862 - val_accuracy: 0.8388\n",
      "Epoch 25/300\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.4095 - accuracy: 0.8332 - val_loss: 0.3855 - val_accuracy: 0.8438\n",
      "Epoch 26/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4095 - accuracy: 0.8328 - val_loss: 0.3857 - val_accuracy: 0.8450\n",
      "Epoch 27/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4089 - accuracy: 0.8335 - val_loss: 0.3864 - val_accuracy: 0.8462\n",
      "Epoch 28/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4085 - accuracy: 0.8336 - val_loss: 0.3843 - val_accuracy: 0.8462\n",
      "Epoch 29/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4081 - accuracy: 0.8339 - val_loss: 0.3854 - val_accuracy: 0.8475\n",
      "Epoch 30/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4084 - accuracy: 0.8350 - val_loss: 0.3843 - val_accuracy: 0.8438\n",
      "Epoch 31/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4081 - accuracy: 0.8347 - val_loss: 0.3863 - val_accuracy: 0.8500\n",
      "Epoch 32/300\n",
      "7200/7200 [==============================] - 1s 74us/step - loss: 0.4073 - accuracy: 0.8342 - val_loss: 0.3834 - val_accuracy: 0.8425\n",
      "Epoch 33/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4073 - accuracy: 0.8346 - val_loss: 0.3836 - val_accuracy: 0.8425\n",
      "Epoch 34/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4073 - accuracy: 0.8339 - val_loss: 0.3842 - val_accuracy: 0.8425\n",
      "Epoch 35/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4071 - accuracy: 0.8347 - val_loss: 0.3829 - val_accuracy: 0.8425\n",
      "Epoch 36/300\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.4068 - accuracy: 0.8356 - val_loss: 0.3837 - val_accuracy: 0.8475\n",
      "Epoch 37/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4069 - accuracy: 0.8338 - val_loss: 0.3839 - val_accuracy: 0.8500\n",
      "Epoch 38/300\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.4067 - accuracy: 0.8333 - val_loss: 0.3834 - val_accuracy: 0.8425\n",
      "Epoch 39/300\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.4062 - accuracy: 0.8336 - val_loss: 0.3832 - val_accuracy: 0.8450\n",
      "Epoch 40/300\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.4061 - accuracy: 0.8339 - val_loss: 0.3832 - val_accuracy: 0.8425\n",
      "Epoch 41/300\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.4061 - accuracy: 0.8339 - val_loss: 0.3832 - val_accuracy: 0.8400\n",
      "Epoch 42/300\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.4056 - accuracy: 0.8332 - val_loss: 0.3833 - val_accuracy: 0.8413\n",
      "Epoch 43/300\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.4058 - accuracy: 0.8344 - val_loss: 0.3832 - val_accuracy: 0.8475\n",
      "Epoch 44/300\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.4054 - accuracy: 0.8335 - val_loss: 0.3817 - val_accuracy: 0.8450\n",
      "Epoch 45/300\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.4057 - accuracy: 0.8326 - val_loss: 0.3822 - val_accuracy: 0.8425\n",
      "Epoch 46/300\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.4052 - accuracy: 0.8340 - val_loss: 0.3819 - val_accuracy: 0.8450\n",
      "Epoch 47/300\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.4054 - accuracy: 0.8328 - val_loss: 0.3829 - val_accuracy: 0.8462\n",
      "Epoch 48/300\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.4051 - accuracy: 0.8338 - val_loss: 0.3832 - val_accuracy: 0.8462\n",
      "Epoch 49/300\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.4054 - accuracy: 0.8332 - val_loss: 0.3838 - val_accuracy: 0.8462\n",
      "Epoch 50/300\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.4049 - accuracy: 0.8331 - val_loss: 0.3829 - val_accuracy: 0.8438\n",
      "Epoch 51/300\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.4049 - accuracy: 0.8333 - val_loss: 0.3827 - val_accuracy: 0.8425\n",
      "Epoch 52/300\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.4046 - accuracy: 0.8338 - val_loss: 0.3821 - val_accuracy: 0.8438\n",
      "Epoch 53/300\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.4047 - accuracy: 0.8322 - val_loss: 0.3818 - val_accuracy: 0.8462\n",
      "Epoch 54/300\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.4048 - accuracy: 0.8332 - val_loss: 0.3823 - val_accuracy: 0.8475\n",
      "Epoch 55/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4047 - accuracy: 0.8336 - val_loss: 0.3825 - val_accuracy: 0.8462\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4046 - accuracy: 0.8319 - val_loss: 0.3821 - val_accuracy: 0.8450\n",
      "Epoch 57/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4046 - accuracy: 0.8326 - val_loss: 0.3827 - val_accuracy: 0.8450\n",
      "Epoch 58/300\n",
      "7200/7200 [==============================] - 1s 73us/step - loss: 0.4042 - accuracy: 0.8343 - val_loss: 0.3830 - val_accuracy: 0.8438\n",
      "Epoch 59/300\n",
      "7200/7200 [==============================] - 1s 75us/step - loss: 0.4042 - accuracy: 0.8328 - val_loss: 0.3812 - val_accuracy: 0.8450\n",
      "Epoch 60/300\n",
      "7200/7200 [==============================] - 1s 75us/step - loss: 0.4042 - accuracy: 0.8340 - val_loss: 0.3811 - val_accuracy: 0.8450\n",
      "Epoch 61/300\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.4044 - accuracy: 0.8329 - val_loss: 0.3819 - val_accuracy: 0.8475\n",
      "Epoch 62/300\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.4038 - accuracy: 0.8338 - val_loss: 0.3813 - val_accuracy: 0.8413\n",
      "Epoch 63/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4042 - accuracy: 0.8331 - val_loss: 0.3815 - val_accuracy: 0.8487\n",
      "Epoch 64/300\n",
      "7200/7200 [==============================] - 0s 68us/step - loss: 0.4042 - accuracy: 0.8322 - val_loss: 0.3818 - val_accuracy: 0.8438\n",
      "Epoch 65/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4039 - accuracy: 0.8333 - val_loss: 0.3819 - val_accuracy: 0.8475\n",
      "Epoch 66/300\n",
      "7200/7200 [==============================] - 0s 69us/step - loss: 0.4041 - accuracy: 0.8335 - val_loss: 0.3815 - val_accuracy: 0.8425\n",
      "Epoch 67/300\n",
      "7200/7200 [==============================] - 1s 70us/step - loss: 0.4041 - accuracy: 0.8338 - val_loss: 0.3804 - val_accuracy: 0.8425\n",
      "Epoch 68/300\n",
      "7200/7200 [==============================] - 0s 69us/step - loss: 0.4039 - accuracy: 0.8332 - val_loss: 0.3808 - val_accuracy: 0.8438\n",
      "Epoch 69/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4039 - accuracy: 0.8340 - val_loss: 0.3810 - val_accuracy: 0.8475\n",
      "Epoch 70/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4036 - accuracy: 0.8315 - val_loss: 0.3819 - val_accuracy: 0.8413\n",
      "Epoch 71/300\n",
      "7200/7200 [==============================] - 0s 68us/step - loss: 0.4040 - accuracy: 0.8326 - val_loss: 0.3812 - val_accuracy: 0.8425\n",
      "Epoch 72/300\n",
      "7200/7200 [==============================] - 1s 74us/step - loss: 0.4039 - accuracy: 0.8329 - val_loss: 0.3814 - val_accuracy: 0.8400\n",
      "Epoch 73/300\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.4035 - accuracy: 0.8343 - val_loss: 0.3812 - val_accuracy: 0.8450\n",
      "Epoch 74/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4036 - accuracy: 0.8321 - val_loss: 0.3801 - val_accuracy: 0.8462\n",
      "Epoch 75/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4037 - accuracy: 0.8322 - val_loss: 0.3821 - val_accuracy: 0.8462\n",
      "Epoch 76/300\n",
      "7200/7200 [==============================] - 1s 75us/step - loss: 0.4036 - accuracy: 0.8342 - val_loss: 0.3814 - val_accuracy: 0.8425\n",
      "Epoch 77/300\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.4036 - accuracy: 0.8329 - val_loss: 0.3816 - val_accuracy: 0.8425\n",
      "Epoch 78/300\n",
      "7200/7200 [==============================] - 0s 68us/step - loss: 0.4036 - accuracy: 0.8338 - val_loss: 0.3828 - val_accuracy: 0.8475\n",
      "Epoch 79/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4033 - accuracy: 0.8332 - val_loss: 0.3803 - val_accuracy: 0.8438\n",
      "Epoch 80/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4036 - accuracy: 0.8335 - val_loss: 0.3802 - val_accuracy: 0.8425\n",
      "Epoch 81/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4033 - accuracy: 0.8343 - val_loss: 0.3813 - val_accuracy: 0.8500\n",
      "Epoch 82/300\n",
      "7200/7200 [==============================] - 1s 71us/step - loss: 0.4032 - accuracy: 0.8329 - val_loss: 0.3814 - val_accuracy: 0.8475\n",
      "Epoch 83/300\n",
      "7200/7200 [==============================] - 0s 69us/step - loss: 0.4035 - accuracy: 0.8336 - val_loss: 0.3812 - val_accuracy: 0.8450\n",
      "Epoch 84/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4032 - accuracy: 0.8324 - val_loss: 0.3812 - val_accuracy: 0.8450\n",
      "Epoch 85/300\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.4031 - accuracy: 0.8331 - val_loss: 0.3804 - val_accuracy: 0.8425\n",
      "Epoch 86/300\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.4033 - accuracy: 0.8338 - val_loss: 0.3801 - val_accuracy: 0.8487\n",
      "Epoch 87/300\n",
      "7200/7200 [==============================] - 1s 73us/step - loss: 0.4029 - accuracy: 0.8324 - val_loss: 0.3799 - val_accuracy: 0.8450\n",
      "Epoch 88/300\n",
      "7200/7200 [==============================] - 1s 70us/step - loss: 0.4031 - accuracy: 0.8344 - val_loss: 0.3802 - val_accuracy: 0.8438\n",
      "Epoch 89/300\n",
      "7200/7200 [==============================] - 1s 71us/step - loss: 0.4032 - accuracy: 0.8336 - val_loss: 0.3797 - val_accuracy: 0.8438\n",
      "Epoch 90/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4032 - accuracy: 0.8336 - val_loss: 0.3791 - val_accuracy: 0.8438\n",
      "Epoch 91/300\n",
      "7200/7200 [==============================] - 0s 68us/step - loss: 0.4029 - accuracy: 0.8340 - val_loss: 0.3818 - val_accuracy: 0.8462\n",
      "Epoch 92/300\n",
      "7200/7200 [==============================] - 0s 66us/step - loss: 0.4031 - accuracy: 0.8328 - val_loss: 0.3799 - val_accuracy: 0.8438\n",
      "Epoch 93/300\n",
      "7200/7200 [==============================] - 1s 71us/step - loss: 0.4029 - accuracy: 0.8349 - val_loss: 0.3798 - val_accuracy: 0.8438\n",
      "Epoch 94/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4030 - accuracy: 0.8340 - val_loss: 0.3803 - val_accuracy: 0.8450\n",
      "Epoch 95/300\n",
      "7200/7200 [==============================] - 1s 73us/step - loss: 0.4028 - accuracy: 0.8332 - val_loss: 0.3794 - val_accuracy: 0.8450\n",
      "Epoch 96/300\n",
      "7200/7200 [==============================] - 0s 68us/step - loss: 0.4030 - accuracy: 0.8336 - val_loss: 0.3796 - val_accuracy: 0.8450\n",
      "Epoch 97/300\n",
      "7200/7200 [==============================] - 1s 71us/step - loss: 0.4029 - accuracy: 0.8328 - val_loss: 0.3799 - val_accuracy: 0.8438\n",
      "Epoch 98/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4026 - accuracy: 0.8342 - val_loss: 0.3833 - val_accuracy: 0.8512\n",
      "Epoch 99/300\n",
      "7200/7200 [==============================] - 1s 71us/step - loss: 0.4031 - accuracy: 0.8342 - val_loss: 0.3802 - val_accuracy: 0.8425\n",
      "Epoch 100/300\n",
      "7200/7200 [==============================] - 1s 71us/step - loss: 0.4029 - accuracy: 0.8343 - val_loss: 0.3798 - val_accuracy: 0.8462\n",
      "Epoch 101/300\n",
      "7200/7200 [==============================] - 1s 71us/step - loss: 0.4026 - accuracy: 0.8318 - val_loss: 0.3805 - val_accuracy: 0.8487\n",
      "Epoch 102/300\n",
      "7200/7200 [==============================] - 1s 71us/step - loss: 0.4030 - accuracy: 0.8336 - val_loss: 0.3793 - val_accuracy: 0.8438\n",
      "Epoch 103/300\n",
      "7200/7200 [==============================] - 1s 71us/step - loss: 0.4026 - accuracy: 0.8333 - val_loss: 0.3802 - val_accuracy: 0.8425\n",
      "Epoch 104/300\n",
      "7200/7200 [==============================] - 1s 70us/step - loss: 0.4025 - accuracy: 0.8332 - val_loss: 0.3797 - val_accuracy: 0.8438\n",
      "Epoch 105/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4027 - accuracy: 0.8331 - val_loss: 0.3796 - val_accuracy: 0.8450\n",
      "Epoch 106/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4021 - accuracy: 0.8354 - val_loss: 0.3810 - val_accuracy: 0.8487\n",
      "Epoch 107/300\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.4026 - accuracy: 0.8336 - val_loss: 0.3806 - val_accuracy: 0.8375\n",
      "Epoch 108/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4026 - accuracy: 0.8336 - val_loss: 0.3790 - val_accuracy: 0.8425\n",
      "Epoch 109/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4023 - accuracy: 0.8343 - val_loss: 0.3781 - val_accuracy: 0.8425\n",
      "Epoch 110/300\n",
      "7200/7200 [==============================] - 1s 74us/step - loss: 0.4027 - accuracy: 0.8338 - val_loss: 0.3790 - val_accuracy: 0.8462\n",
      "Epoch 111/300\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.4025 - accuracy: 0.8331 - val_loss: 0.3788 - val_accuracy: 0.8450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/300\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.4027 - accuracy: 0.8317 - val_loss: 0.3793 - val_accuracy: 0.8438\n",
      "Epoch 113/300\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.4025 - accuracy: 0.8343 - val_loss: 0.3791 - val_accuracy: 0.8462\n",
      "Epoch 114/300\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.4023 - accuracy: 0.8332 - val_loss: 0.3795 - val_accuracy: 0.8450\n",
      "Epoch 115/300\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.4023 - accuracy: 0.8338 - val_loss: 0.3791 - val_accuracy: 0.8438\n",
      "Epoch 116/300\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.4022 - accuracy: 0.8325 - val_loss: 0.3794 - val_accuracy: 0.8450\n",
      "Epoch 117/300\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.4021 - accuracy: 0.8351 - val_loss: 0.3804 - val_accuracy: 0.8462\n",
      "Epoch 118/300\n",
      "7200/7200 [==============================] - 1s 74us/step - loss: 0.4024 - accuracy: 0.8339 - val_loss: 0.3792 - val_accuracy: 0.8438\n",
      "Epoch 119/300\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.4021 - accuracy: 0.8329 - val_loss: 0.3799 - val_accuracy: 0.8400\n",
      "Epoch 120/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4021 - accuracy: 0.8328 - val_loss: 0.3788 - val_accuracy: 0.8425\n",
      "Epoch 121/300\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.4021 - accuracy: 0.8351 - val_loss: 0.3807 - val_accuracy: 0.8450\n",
      "Epoch 122/300\n",
      "7200/7200 [==============================] - 1s 75us/step - loss: 0.4025 - accuracy: 0.8343 - val_loss: 0.3797 - val_accuracy: 0.8388\n",
      "Epoch 123/300\n",
      "7200/7200 [==============================] - 1s 73us/step - loss: 0.4025 - accuracy: 0.8335 - val_loss: 0.3795 - val_accuracy: 0.8462\n",
      "Epoch 124/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4023 - accuracy: 0.8344 - val_loss: 0.3793 - val_accuracy: 0.8450\n",
      "Epoch 125/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4021 - accuracy: 0.8346 - val_loss: 0.3811 - val_accuracy: 0.8462\n",
      "Epoch 126/300\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.4019 - accuracy: 0.8344 - val_loss: 0.3806 - val_accuracy: 0.8475\n",
      "Epoch 127/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4020 - accuracy: 0.8340 - val_loss: 0.3795 - val_accuracy: 0.8462\n",
      "Epoch 128/300\n",
      "7200/7200 [==============================] - 1s 75us/step - loss: 0.4022 - accuracy: 0.8319 - val_loss: 0.3788 - val_accuracy: 0.8450\n",
      "Epoch 129/300\n",
      "7200/7200 [==============================] - 1s 73us/step - loss: 0.4020 - accuracy: 0.8340 - val_loss: 0.3786 - val_accuracy: 0.8438\n",
      "Epoch 130/300\n",
      "7200/7200 [==============================] - 1s 74us/step - loss: 0.4020 - accuracy: 0.8342 - val_loss: 0.3798 - val_accuracy: 0.8487\n",
      "Epoch 131/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4017 - accuracy: 0.8343 - val_loss: 0.3791 - val_accuracy: 0.8438\n",
      "Epoch 132/300\n",
      "7200/7200 [==============================] - 1s 73us/step - loss: 0.4018 - accuracy: 0.8339 - val_loss: 0.3793 - val_accuracy: 0.8438\n",
      "Epoch 133/300\n",
      "7200/7200 [==============================] - 1s 71us/step - loss: 0.4020 - accuracy: 0.8354 - val_loss: 0.3799 - val_accuracy: 0.8475\n",
      "Epoch 134/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4022 - accuracy: 0.8343 - val_loss: 0.3789 - val_accuracy: 0.8425\n",
      "Epoch 135/300\n",
      "7200/7200 [==============================] - 1s 73us/step - loss: 0.4018 - accuracy: 0.8344 - val_loss: 0.3796 - val_accuracy: 0.8475\n",
      "Epoch 136/300\n",
      "7200/7200 [==============================] - 1s 74us/step - loss: 0.4017 - accuracy: 0.8339 - val_loss: 0.3798 - val_accuracy: 0.8425\n",
      "Epoch 137/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4016 - accuracy: 0.8339 - val_loss: 0.3798 - val_accuracy: 0.8475\n",
      "Epoch 138/300\n",
      "7200/7200 [==============================] - 1s 74us/step - loss: 0.4020 - accuracy: 0.8343 - val_loss: 0.3798 - val_accuracy: 0.8438\n",
      "Epoch 139/300\n",
      "7200/7200 [==============================] - 1s 75us/step - loss: 0.4019 - accuracy: 0.8342 - val_loss: 0.3795 - val_accuracy: 0.8462\n",
      "Epoch 140/300\n",
      "7200/7200 [==============================] - 1s 74us/step - loss: 0.4019 - accuracy: 0.8328 - val_loss: 0.3791 - val_accuracy: 0.8450\n",
      "Epoch 141/300\n",
      "7200/7200 [==============================] - 1s 73us/step - loss: 0.4019 - accuracy: 0.8339 - val_loss: 0.3791 - val_accuracy: 0.8413\n",
      "Epoch 142/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4021 - accuracy: 0.8349 - val_loss: 0.3791 - val_accuracy: 0.8425\n",
      "Epoch 143/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4017 - accuracy: 0.8339 - val_loss: 0.3794 - val_accuracy: 0.8475\n",
      "Epoch 144/300\n",
      "7200/7200 [==============================] - 1s 73us/step - loss: 0.4016 - accuracy: 0.8318 - val_loss: 0.3785 - val_accuracy: 0.8425\n",
      "Epoch 145/300\n",
      "7200/7200 [==============================] - 1s 74us/step - loss: 0.4021 - accuracy: 0.8360 - val_loss: 0.3789 - val_accuracy: 0.8413\n",
      "Epoch 146/300\n",
      "7200/7200 [==============================] - 1s 73us/step - loss: 0.4018 - accuracy: 0.8344 - val_loss: 0.3784 - val_accuracy: 0.8438\n",
      "Epoch 147/300\n",
      "7200/7200 [==============================] - 1s 74us/step - loss: 0.4016 - accuracy: 0.8332 - val_loss: 0.3797 - val_accuracy: 0.8413\n",
      "Epoch 148/300\n",
      "7200/7200 [==============================] - 1s 70us/step - loss: 0.4017 - accuracy: 0.8343 - val_loss: 0.3792 - val_accuracy: 0.8425\n",
      "Epoch 149/300\n",
      "7200/7200 [==============================] - 0s 69us/step - loss: 0.4016 - accuracy: 0.8340 - val_loss: 0.3792 - val_accuracy: 0.8425\n",
      "Epoch 150/300\n",
      "7200/7200 [==============================] - 1s 73us/step - loss: 0.4017 - accuracy: 0.8342 - val_loss: 0.3798 - val_accuracy: 0.8413\n",
      "Epoch 151/300\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.4017 - accuracy: 0.8354 - val_loss: 0.3793 - val_accuracy: 0.8462\n",
      "Epoch 152/300\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.4018 - accuracy: 0.8357 - val_loss: 0.3801 - val_accuracy: 0.8450\n",
      "Epoch 153/300\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.4018 - accuracy: 0.8344 - val_loss: 0.3801 - val_accuracy: 0.8462\n",
      "Epoch 154/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4020 - accuracy: 0.8325 - val_loss: 0.3800 - val_accuracy: 0.8512\n",
      "Epoch 155/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4015 - accuracy: 0.8350 - val_loss: 0.3793 - val_accuracy: 0.8512\n",
      "Epoch 156/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4015 - accuracy: 0.8336 - val_loss: 0.3793 - val_accuracy: 0.8425\n",
      "Epoch 157/300\n",
      "7200/7200 [==============================] - 0s 69us/step - loss: 0.4013 - accuracy: 0.8347 - val_loss: 0.3807 - val_accuracy: 0.8500\n",
      "Epoch 158/300\n",
      "7200/7200 [==============================] - 1s 71us/step - loss: 0.4015 - accuracy: 0.8340 - val_loss: 0.3791 - val_accuracy: 0.8450\n",
      "Epoch 159/300\n",
      "7200/7200 [==============================] - 0s 69us/step - loss: 0.4012 - accuracy: 0.8351 - val_loss: 0.3802 - val_accuracy: 0.8487\n",
      "Epoch 160/300\n",
      "7200/7200 [==============================] - 1s 71us/step - loss: 0.4016 - accuracy: 0.8351 - val_loss: 0.3810 - val_accuracy: 0.8525\n",
      "Epoch 161/300\n",
      "7200/7200 [==============================] - 1s 75us/step - loss: 0.4016 - accuracy: 0.8343 - val_loss: 0.3799 - val_accuracy: 0.8450\n",
      "Epoch 162/300\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.4018 - accuracy: 0.8339 - val_loss: 0.3797 - val_accuracy: 0.8475\n",
      "Epoch 163/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4017 - accuracy: 0.8340 - val_loss: 0.3790 - val_accuracy: 0.8462\n",
      "Epoch 164/300\n",
      "7200/7200 [==============================] - 1s 74us/step - loss: 0.4014 - accuracy: 0.8361 - val_loss: 0.3794 - val_accuracy: 0.8525\n",
      "Epoch 165/300\n",
      "7200/7200 [==============================] - 1s 70us/step - loss: 0.4019 - accuracy: 0.8333 - val_loss: 0.3788 - val_accuracy: 0.8438\n",
      "Epoch 166/300\n",
      "7200/7200 [==============================] - 1s 70us/step - loss: 0.4018 - accuracy: 0.8357 - val_loss: 0.3800 - val_accuracy: 0.8500\n",
      "Epoch 167/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 65us/step - loss: 0.4013 - accuracy: 0.8343 - val_loss: 0.3788 - val_accuracy: 0.8438\n",
      "Epoch 168/300\n",
      "7200/7200 [==============================] - 0s 65us/step - loss: 0.4018 - accuracy: 0.8340 - val_loss: 0.3799 - val_accuracy: 0.8525\n",
      "Epoch 169/300\n",
      "7200/7200 [==============================] - 0s 65us/step - loss: 0.4017 - accuracy: 0.8353 - val_loss: 0.3795 - val_accuracy: 0.8500\n",
      "Epoch 170/300\n",
      "7200/7200 [==============================] - 0s 66us/step - loss: 0.4011 - accuracy: 0.8336 - val_loss: 0.3801 - val_accuracy: 0.8450\n",
      "Epoch 171/300\n",
      "7200/7200 [==============================] - 0s 66us/step - loss: 0.4019 - accuracy: 0.8326 - val_loss: 0.3791 - val_accuracy: 0.8450\n",
      "Epoch 172/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4014 - accuracy: 0.8344 - val_loss: 0.3810 - val_accuracy: 0.8450\n",
      "Epoch 173/300\n",
      "7200/7200 [==============================] - 0s 65us/step - loss: 0.4016 - accuracy: 0.8346 - val_loss: 0.3800 - val_accuracy: 0.8462\n",
      "Epoch 174/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4014 - accuracy: 0.8331 - val_loss: 0.3796 - val_accuracy: 0.8438\n",
      "Epoch 175/300\n",
      "7200/7200 [==============================] - 1s 73us/step - loss: 0.4013 - accuracy: 0.8328 - val_loss: 0.3793 - val_accuracy: 0.8450\n",
      "Epoch 176/300\n",
      "7200/7200 [==============================] - 0s 66us/step - loss: 0.4013 - accuracy: 0.8347 - val_loss: 0.3786 - val_accuracy: 0.8438\n",
      "Epoch 177/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4013 - accuracy: 0.8350 - val_loss: 0.3792 - val_accuracy: 0.8525\n",
      "Epoch 178/300\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.4012 - accuracy: 0.8332 - val_loss: 0.3790 - val_accuracy: 0.8450\n",
      "Epoch 179/300\n",
      "7200/7200 [==============================] - 0s 66us/step - loss: 0.4015 - accuracy: 0.8321 - val_loss: 0.3792 - val_accuracy: 0.8438\n",
      "Epoch 180/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4014 - accuracy: 0.8343 - val_loss: 0.3786 - val_accuracy: 0.8438\n",
      "Epoch 181/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4015 - accuracy: 0.8346 - val_loss: 0.3796 - val_accuracy: 0.8500\n",
      "Epoch 182/300\n",
      "7200/7200 [==============================] - 0s 66us/step - loss: 0.4014 - accuracy: 0.8349 - val_loss: 0.3795 - val_accuracy: 0.8450\n",
      "Epoch 183/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4017 - accuracy: 0.8338 - val_loss: 0.3792 - val_accuracy: 0.8438\n",
      "Epoch 184/300\n",
      "7200/7200 [==============================] - 0s 65us/step - loss: 0.4015 - accuracy: 0.8367 - val_loss: 0.3795 - val_accuracy: 0.8487\n",
      "Epoch 185/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4015 - accuracy: 0.8346 - val_loss: 0.3791 - val_accuracy: 0.8487\n",
      "Epoch 186/300\n",
      "7200/7200 [==============================] - 0s 68us/step - loss: 0.4014 - accuracy: 0.8347 - val_loss: 0.3790 - val_accuracy: 0.8475\n",
      "Epoch 187/300\n",
      "7200/7200 [==============================] - 0s 66us/step - loss: 0.4015 - accuracy: 0.8338 - val_loss: 0.3794 - val_accuracy: 0.8438\n",
      "Epoch 188/300\n",
      "7200/7200 [==============================] - 0s 65us/step - loss: 0.4013 - accuracy: 0.8343 - val_loss: 0.3794 - val_accuracy: 0.8450\n",
      "Epoch 189/300\n",
      "7200/7200 [==============================] - 0s 65us/step - loss: 0.4014 - accuracy: 0.8335 - val_loss: 0.3796 - val_accuracy: 0.8475\n",
      "Epoch 190/300\n",
      "7200/7200 [==============================] - 1s 70us/step - loss: 0.4012 - accuracy: 0.8351 - val_loss: 0.3783 - val_accuracy: 0.8438\n",
      "Epoch 191/300\n",
      "7200/7200 [==============================] - 0s 66us/step - loss: 0.4015 - accuracy: 0.8343 - val_loss: 0.3786 - val_accuracy: 0.8438\n",
      "Epoch 192/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4015 - accuracy: 0.8338 - val_loss: 0.3793 - val_accuracy: 0.8512\n",
      "Epoch 193/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4015 - accuracy: 0.8342 - val_loss: 0.3791 - val_accuracy: 0.8475\n",
      "Epoch 194/300\n",
      "7200/7200 [==============================] - 0s 68us/step - loss: 0.4007 - accuracy: 0.8342 - val_loss: 0.3802 - val_accuracy: 0.8425\n",
      "Epoch 195/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4012 - accuracy: 0.8338 - val_loss: 0.3780 - val_accuracy: 0.8475\n",
      "Epoch 196/300\n",
      "7200/7200 [==============================] - 1s 73us/step - loss: 0.4015 - accuracy: 0.8332 - val_loss: 0.3791 - val_accuracy: 0.8462\n",
      "Epoch 197/300\n",
      "7200/7200 [==============================] - 0s 66us/step - loss: 0.4011 - accuracy: 0.8363 - val_loss: 0.3793 - val_accuracy: 0.8512\n",
      "Epoch 198/300\n",
      "7200/7200 [==============================] - 0s 65us/step - loss: 0.4013 - accuracy: 0.8346 - val_loss: 0.3789 - val_accuracy: 0.8438\n",
      "Epoch 199/300\n",
      "7200/7200 [==============================] - 0s 65us/step - loss: 0.4016 - accuracy: 0.8329 - val_loss: 0.3800 - val_accuracy: 0.8438\n",
      "Epoch 200/300\n",
      "7200/7200 [==============================] - 0s 65us/step - loss: 0.4012 - accuracy: 0.8333 - val_loss: 0.3802 - val_accuracy: 0.8462\n",
      "Epoch 201/300\n",
      "7200/7200 [==============================] - 0s 66us/step - loss: 0.4018 - accuracy: 0.8336 - val_loss: 0.3801 - val_accuracy: 0.8425\n",
      "Epoch 202/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4015 - accuracy: 0.8340 - val_loss: 0.3796 - val_accuracy: 0.8438\n",
      "Epoch 203/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4010 - accuracy: 0.8339 - val_loss: 0.3807 - val_accuracy: 0.8525\n",
      "Epoch 204/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4013 - accuracy: 0.8340 - val_loss: 0.3798 - val_accuracy: 0.8438\n",
      "Epoch 205/300\n",
      "7200/7200 [==============================] - 1s 70us/step - loss: 0.4012 - accuracy: 0.8332 - val_loss: 0.3790 - val_accuracy: 0.8438\n",
      "Epoch 206/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4013 - accuracy: 0.8347 - val_loss: 0.3790 - val_accuracy: 0.8425\n",
      "Epoch 207/300\n",
      "7200/7200 [==============================] - 0s 68us/step - loss: 0.4014 - accuracy: 0.8339 - val_loss: 0.3796 - val_accuracy: 0.8450\n",
      "Epoch 208/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4012 - accuracy: 0.8336 - val_loss: 0.3792 - val_accuracy: 0.8475\n",
      "Epoch 209/300\n",
      "7200/7200 [==============================] - 0s 68us/step - loss: 0.4013 - accuracy: 0.8328 - val_loss: 0.3790 - val_accuracy: 0.8487\n",
      "Epoch 210/300\n",
      "7200/7200 [==============================] - 1s 70us/step - loss: 0.4015 - accuracy: 0.8347 - val_loss: 0.3804 - val_accuracy: 0.8462\n",
      "Epoch 211/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4016 - accuracy: 0.8335 - val_loss: 0.3795 - val_accuracy: 0.8500\n",
      "Epoch 212/300\n",
      "7200/7200 [==============================] - 0s 66us/step - loss: 0.4014 - accuracy: 0.8335 - val_loss: 0.3794 - val_accuracy: 0.8475\n",
      "Epoch 213/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4017 - accuracy: 0.8328 - val_loss: 0.3793 - val_accuracy: 0.8438\n",
      "Epoch 214/300\n",
      "7200/7200 [==============================] - 1s 70us/step - loss: 0.4012 - accuracy: 0.8347 - val_loss: 0.3797 - val_accuracy: 0.8487\n",
      "Epoch 215/300\n",
      "7200/7200 [==============================] - 0s 66us/step - loss: 0.4010 - accuracy: 0.8328 - val_loss: 0.3792 - val_accuracy: 0.8500\n",
      "Epoch 216/300\n",
      "7200/7200 [==============================] - 0s 69us/step - loss: 0.4014 - accuracy: 0.8351 - val_loss: 0.3797 - val_accuracy: 0.8425\n",
      "Epoch 217/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4017 - accuracy: 0.8329 - val_loss: 0.3801 - val_accuracy: 0.8475\n",
      "Epoch 218/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4011 - accuracy: 0.8336 - val_loss: 0.3789 - val_accuracy: 0.8450\n",
      "Epoch 219/300\n",
      "7200/7200 [==============================] - 1s 71us/step - loss: 0.4009 - accuracy: 0.8342 - val_loss: 0.3801 - val_accuracy: 0.8487\n",
      "Epoch 220/300\n",
      "7200/7200 [==============================] - 0s 66us/step - loss: 0.4015 - accuracy: 0.8342 - val_loss: 0.3792 - val_accuracy: 0.8462\n",
      "Epoch 221/300\n",
      "7200/7200 [==============================] - 1s 71us/step - loss: 0.4007 - accuracy: 0.8329 - val_loss: 0.3795 - val_accuracy: 0.8438\n",
      "Epoch 222/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 66us/step - loss: 0.4014 - accuracy: 0.8335 - val_loss: 0.3802 - val_accuracy: 0.8487\n",
      "Epoch 223/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4014 - accuracy: 0.8326 - val_loss: 0.3794 - val_accuracy: 0.8487\n",
      "Epoch 224/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4012 - accuracy: 0.8351 - val_loss: 0.3790 - val_accuracy: 0.8475\n",
      "Epoch 225/300\n",
      "7200/7200 [==============================] - 0s 68us/step - loss: 0.4011 - accuracy: 0.8338 - val_loss: 0.3809 - val_accuracy: 0.8500\n",
      "Epoch 226/300\n",
      "7200/7200 [==============================] - 0s 66us/step - loss: 0.4011 - accuracy: 0.8339 - val_loss: 0.3796 - val_accuracy: 0.8450\n",
      "Epoch 227/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4013 - accuracy: 0.8343 - val_loss: 0.3792 - val_accuracy: 0.8487\n",
      "Epoch 228/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4013 - accuracy: 0.8353 - val_loss: 0.3787 - val_accuracy: 0.8462\n",
      "Epoch 229/300\n",
      "7200/7200 [==============================] - 0s 68us/step - loss: 0.4014 - accuracy: 0.8343 - val_loss: 0.3803 - val_accuracy: 0.8438\n",
      "Epoch 230/300\n",
      "7200/7200 [==============================] - 0s 67us/step - loss: 0.4014 - accuracy: 0.8338 - val_loss: 0.3802 - val_accuracy: 0.8462\n",
      "Epoch 231/300\n",
      "7200/7200 [==============================] - 0s 68us/step - loss: 0.4012 - accuracy: 0.8340 - val_loss: 0.3804 - val_accuracy: 0.8438\n",
      "Epoch 232/300\n",
      "7200/7200 [==============================] - 1s 73us/step - loss: 0.4014 - accuracy: 0.8332 - val_loss: 0.3801 - val_accuracy: 0.8450\n",
      "Epoch 233/300\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.4012 - accuracy: 0.8336 - val_loss: 0.3808 - val_accuracy: 0.8438\n",
      "Epoch 234/300\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.4018 - accuracy: 0.8339 - val_loss: 0.3794 - val_accuracy: 0.8475\n",
      "Epoch 235/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4014 - accuracy: 0.8331 - val_loss: 0.3793 - val_accuracy: 0.8450\n",
      "Epoch 236/300\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.4014 - accuracy: 0.8329 - val_loss: 0.3793 - val_accuracy: 0.8462\n",
      "Epoch 237/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4010 - accuracy: 0.8335 - val_loss: 0.3785 - val_accuracy: 0.8462\n",
      "Epoch 238/300\n",
      "7200/7200 [==============================] - 1s 75us/step - loss: 0.4013 - accuracy: 0.8342 - val_loss: 0.3790 - val_accuracy: 0.8487\n",
      "Epoch 239/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4012 - accuracy: 0.8340 - val_loss: 0.3800 - val_accuracy: 0.8438\n",
      "Epoch 240/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4011 - accuracy: 0.8332 - val_loss: 0.3792 - val_accuracy: 0.8438\n",
      "Epoch 241/300\n",
      "7200/7200 [==============================] - 1s 75us/step - loss: 0.4013 - accuracy: 0.8339 - val_loss: 0.3795 - val_accuracy: 0.8462\n",
      "Epoch 242/300\n",
      "7200/7200 [==============================] - 1s 75us/step - loss: 0.4009 - accuracy: 0.8339 - val_loss: 0.3800 - val_accuracy: 0.8438\n",
      "Epoch 243/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4011 - accuracy: 0.8346 - val_loss: 0.3798 - val_accuracy: 0.8438\n",
      "Epoch 244/300\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.4013 - accuracy: 0.8342 - val_loss: 0.3803 - val_accuracy: 0.8425\n",
      "Epoch 245/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4012 - accuracy: 0.8344 - val_loss: 0.3800 - val_accuracy: 0.8450\n",
      "Epoch 246/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4013 - accuracy: 0.8338 - val_loss: 0.3793 - val_accuracy: 0.8450\n",
      "Epoch 247/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4014 - accuracy: 0.8347 - val_loss: 0.3790 - val_accuracy: 0.8450\n",
      "Epoch 248/300\n",
      "7200/7200 [==============================] - 1s 74us/step - loss: 0.4014 - accuracy: 0.8342 - val_loss: 0.3795 - val_accuracy: 0.8450\n",
      "Epoch 249/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4011 - accuracy: 0.8349 - val_loss: 0.3793 - val_accuracy: 0.8425\n",
      "Epoch 250/300\n",
      "7200/7200 [==============================] - 1s 75us/step - loss: 0.4014 - accuracy: 0.8343 - val_loss: 0.3807 - val_accuracy: 0.8413\n",
      "Epoch 251/300\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.4016 - accuracy: 0.8360 - val_loss: 0.3801 - val_accuracy: 0.8487\n",
      "Epoch 252/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4011 - accuracy: 0.8344 - val_loss: 0.3790 - val_accuracy: 0.8462\n",
      "Epoch 253/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4010 - accuracy: 0.8346 - val_loss: 0.3800 - val_accuracy: 0.8450\n",
      "Epoch 254/300\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.4009 - accuracy: 0.8335 - val_loss: 0.3809 - val_accuracy: 0.8438\n",
      "Epoch 255/300\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.4014 - accuracy: 0.8347 - val_loss: 0.3802 - val_accuracy: 0.8438\n",
      "Epoch 256/300\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.4017 - accuracy: 0.8342 - val_loss: 0.3801 - val_accuracy: 0.8400\n",
      "Epoch 257/300\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.4013 - accuracy: 0.8344 - val_loss: 0.3809 - val_accuracy: 0.8450\n",
      "Epoch 258/300\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.4012 - accuracy: 0.8346 - val_loss: 0.3808 - val_accuracy: 0.8438\n",
      "Epoch 259/300\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.4011 - accuracy: 0.8344 - val_loss: 0.3802 - val_accuracy: 0.8450\n",
      "Epoch 260/300\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.4012 - accuracy: 0.8346 - val_loss: 0.3792 - val_accuracy: 0.8425\n",
      "Epoch 261/300\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.4011 - accuracy: 0.8350 - val_loss: 0.3797 - val_accuracy: 0.8450\n",
      "Epoch 262/300\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.4012 - accuracy: 0.8354 - val_loss: 0.3782 - val_accuracy: 0.8475\n",
      "Epoch 263/300\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.4010 - accuracy: 0.8332 - val_loss: 0.3793 - val_accuracy: 0.8462\n",
      "Epoch 264/300\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.4012 - accuracy: 0.8360 - val_loss: 0.3795 - val_accuracy: 0.8425\n",
      "Epoch 265/300\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.4013 - accuracy: 0.8354 - val_loss: 0.3793 - val_accuracy: 0.8462\n",
      "Epoch 266/300\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.4013 - accuracy: 0.8346 - val_loss: 0.3796 - val_accuracy: 0.8475\n",
      "Epoch 267/300\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.4007 - accuracy: 0.8356 - val_loss: 0.3807 - val_accuracy: 0.8525\n",
      "Epoch 268/300\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.4010 - accuracy: 0.8349 - val_loss: 0.3794 - val_accuracy: 0.8438\n",
      "Epoch 269/300\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.4011 - accuracy: 0.8349 - val_loss: 0.3802 - val_accuracy: 0.8487\n",
      "Epoch 270/300\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.4014 - accuracy: 0.8343 - val_loss: 0.3790 - val_accuracy: 0.8438\n",
      "Epoch 271/300\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.4010 - accuracy: 0.8358 - val_loss: 0.3794 - val_accuracy: 0.8413\n",
      "Epoch 272/300\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.4011 - accuracy: 0.8342 - val_loss: 0.3795 - val_accuracy: 0.8425\n",
      "Epoch 273/300\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.4013 - accuracy: 0.8333 - val_loss: 0.3799 - val_accuracy: 0.8438\n",
      "Epoch 274/300\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.4009 - accuracy: 0.8349 - val_loss: 0.3784 - val_accuracy: 0.8450\n",
      "Epoch 275/300\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.4015 - accuracy: 0.8350 - val_loss: 0.3792 - val_accuracy: 0.8425\n",
      "Epoch 276/300\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.4009 - accuracy: 0.8340 - val_loss: 0.3796 - val_accuracy: 0.8462\n",
      "Epoch 277/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.4009 - accuracy: 0.8360 - val_loss: 0.3808 - val_accuracy: 0.8512\n",
      "Epoch 278/300\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.4015 - accuracy: 0.8344 - val_loss: 0.3794 - val_accuracy: 0.8438\n",
      "Epoch 279/300\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.4009 - accuracy: 0.8344 - val_loss: 0.3800 - val_accuracy: 0.8462\n",
      "Epoch 280/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4012 - accuracy: 0.8349 - val_loss: 0.3791 - val_accuracy: 0.8438\n",
      "Epoch 281/300\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.4013 - accuracy: 0.8340 - val_loss: 0.3790 - val_accuracy: 0.8475\n",
      "Epoch 282/300\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.4006 - accuracy: 0.8344 - val_loss: 0.3801 - val_accuracy: 0.8425\n",
      "Epoch 283/300\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.4016 - accuracy: 0.8332 - val_loss: 0.3794 - val_accuracy: 0.8462\n",
      "Epoch 284/300\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.4011 - accuracy: 0.8344 - val_loss: 0.3811 - val_accuracy: 0.8438\n",
      "Epoch 285/300\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.4008 - accuracy: 0.8354 - val_loss: 0.3806 - val_accuracy: 0.8413\n",
      "Epoch 286/300\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.4011 - accuracy: 0.8343 - val_loss: 0.3814 - val_accuracy: 0.8512\n",
      "Epoch 287/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4008 - accuracy: 0.8342 - val_loss: 0.3796 - val_accuracy: 0.8450\n",
      "Epoch 288/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4012 - accuracy: 0.8351 - val_loss: 0.3789 - val_accuracy: 0.8462\n",
      "Epoch 289/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4007 - accuracy: 0.8340 - val_loss: 0.3800 - val_accuracy: 0.8462\n",
      "Epoch 290/300\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.4010 - accuracy: 0.8336 - val_loss: 0.3805 - val_accuracy: 0.8438\n",
      "Epoch 291/300\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.4012 - accuracy: 0.8342 - val_loss: 0.3802 - val_accuracy: 0.8462\n",
      "Epoch 292/300\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.4010 - accuracy: 0.8335 - val_loss: 0.3794 - val_accuracy: 0.8450\n",
      "Epoch 293/300\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.4008 - accuracy: 0.8339 - val_loss: 0.3793 - val_accuracy: 0.8487\n",
      "Epoch 294/300\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.4011 - accuracy: 0.8342 - val_loss: 0.3791 - val_accuracy: 0.8450\n",
      "Epoch 295/300\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.4013 - accuracy: 0.8346 - val_loss: 0.3793 - val_accuracy: 0.8425\n",
      "Epoch 296/300\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.4013 - accuracy: 0.8343 - val_loss: 0.3792 - val_accuracy: 0.8450\n",
      "Epoch 297/300\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.4009 - accuracy: 0.8339 - val_loss: 0.3802 - val_accuracy: 0.8462\n",
      "Epoch 298/300\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.4012 - accuracy: 0.8346 - val_loss: 0.3788 - val_accuracy: 0.8475\n",
      "Epoch 299/300\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.4011 - accuracy: 0.8333 - val_loss: 0.3786 - val_accuracy: 0.8450\n",
      "Epoch 300/300\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.4016 - accuracy: 0.8338 - val_loss: 0.3802 - val_accuracy: 0.8487\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(X_train, y_train, validation_split=0.1, batch_size=25, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25349383048>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], linewidth=3)\n",
    "plt.plot(history.history['val_accuracy'], color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of X_test\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making them to 0 and 1 instead of probabs\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1550,   45],\n",
       "       [ 266,  139]], dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating the confusion matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (1551 + 128)/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8395"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the accuracy of the unseen test set\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x20b84e0f3c8>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now what if we want to do a manual input\n",
    "\n",
    "# create the input matrix similar to X_train\n",
    "new_input = [[0.0, 0.0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scale it\n",
    "new_input_scaled = sc.transform(new_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5698444 , -0.57369368, -0.52111599,  0.91601335,  0.10961719,\n",
       "        -0.68538967, -0.2569057 ,  0.8095029 ,  0.64259497,  0.9687384 ,\n",
       "        -0.87203322]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_input_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He will stay with the bank\n",
      "Percentage of chance that we will leave the bank is  6.138348951935768 %\n"
     ]
    }
   ],
   "source": [
    "# Predict using the classifier\n",
    "\n",
    "answer = classifier.predict(new_input_scaled)\n",
    "if answer[0][0] > 0.5:\n",
    "    print('He will leave the ban\"k')\n",
    "else:\n",
    "    print('He will stay with the bank')\n",
    "print('Percentage of chance that we will leave the bank is ', answer[0][0]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize weights to HDF5\n",
    "classifier.save_weights(\"modelclass.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "###---------------LATER-----------------\n",
    "# load weights into new model\n",
    "classifier.load_weights(\"modelclass.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
